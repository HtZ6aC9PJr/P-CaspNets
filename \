#include <vector>
#include <math.h> 
#include <cfloat>

//#include "thrust/device_vector.h"
#include "caffe/layers/cap_layer.hpp"
#include "caffe/filler.hpp"
#include "caffe/util/math_functions.hpp"

namespace caffe {
template <typename Dtype>
__global__ void kernel_channel_max(const int num, const int channels,
    const int spatial_dim, const Dtype* data, Dtype* out) {
  CUDA_KERNEL_LOOP(index, num * spatial_dim) {
    int n = index / spatial_dim;
    int s = index % spatial_dim;
    Dtype maxval = -FLT_MAX;
    for (int c = 0; c < channels; ++c) {
      maxval = max(data[(n * channels + c) * spatial_dim + s], maxval);
    }
    out[index] = maxval;
  }
}

template <typename Dtype>
__global__ void kernel_channel_subtract(const int count,
    const int num, const int channels,
    const int spatial_dim, const Dtype* channel_max, Dtype* data) {
  CUDA_KERNEL_LOOP(index, count) {
    int n = index / channels / spatial_dim;
    int s = index % spatial_dim;
    data[index] -= channel_max[n * spatial_dim + s];
  }
}

template <typename Dtype>
__global__ void kernel_exp(const int count, const Dtype* data, Dtype* out) {
  CUDA_KERNEL_LOOP(index, count) {
    out[index] = exp(data[index]);
  }
}

template <typename Dtype>
__global__ void kernel_channel_sum(const int num, const int channels,
    const int spatial_dim, const Dtype* data, Dtype* channel_sum) {
  CUDA_KERNEL_LOOP(index, num * spatial_dim) {
    int n = index / spatial_dim;
    int s = index % spatial_dim;
    Dtype sum = 0;
    for (int c = 0; c < channels; ++c) {
      sum += data[(n * channels + c) * spatial_dim + s];
    }
    channel_sum[index] = sum;
  }
}

template <typename Dtype>
__global__ void kernel_channel_div(const int count,
    const int num, const int channels,
    const int spatial_dim, const Dtype* channel_sum, Dtype* data) {
  CUDA_KERNEL_LOOP(index, count) {
    int n = index / channels / spatial_dim;
    int s = index % spatial_dim;
    data[index] /= channel_sum[n * spatial_dim + s];
  }
}

template<typename Dtype>
void squash(const Dtype* s, const int len, Dtype* v, Dtype* sum){
  caffe_gpu_memcpy(len, s, v);
  caffe_gpu_powx(len, s, Dtype(2), sum);
  Dtype squared_norm;
  caffe_gpu_asum(len, sum, &squared_norm);
  Dtype coefficient = (squared_norm / (squared_norm + 1)) / sqrt(squared_norm);
  // LOG(INFO) << "norm: "<<squared_norm;
  caffe_gpu_scal(len, coefficient, v);
}

template<typename Dtype>
void squash(const int len, Dtype* v, Dtype* sum){
  caffe_gpu_powx(len, v, Dtype(2), sum);
  Dtype squared_norm;
  caffe_gpu_asum(len, sum, &squared_norm);
  // LOG(INFO) << "len: "<<len;
  // LOG(INFO) << "norm: "<<squared_norm;
  Dtype coefficient = (squared_norm / (squared_norm + 1)) / sqrt(squared_norm);
  caffe_gpu_scal(len, coefficient, v);
}

template <typename Dtype>
void CapLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
    const vector<Blob<Dtype>*>& top) {
  const int total_input = input_capsule_num_*input_capsule_dim_;
  const int total_output = output_capsule_num_ * output_capsule_dim_;
  const int routing_num = input_capsule_num_ * output_capsule_num_;
  const Dtype* bottom_data = bottom[0]->gpu_data();
  // shape of weights: input_capsule_num * input_capsule_dim * (output_capsule_num * output_capsule_dim)
  const Dtype* weight = this->blobs_[0]->gpu_data();
  Dtype* bottom_data_copy = bottom_copy_.mutable_gpu_data();
  caffe_gpu_memcpy(M_ * total_input, bottom_data, bottom_data_copy);

  // squash the output of last layer
  Dtype* scale_data = scale_.mutable_gpu_data();
  Dtype* input_cap_vector = input_cap_vector_.mutable_gpu_data();
  Dtype* output_cap_vector = output_cap_vector_.mutable_gpu_data();
  for(int ba = 0; ba < M_; ++ba) {
    for(int i = 0; i < input_capsule_num_; ++i) {
      squash(input_capsule_dim_, bottom_data_copy + ba * total_input + i * input_capsule_dim_, input_cap_vector);
    }
  }
  
  // Calculate u_.
  // Shape of input: input_capsule_num * input_capsule_dim, namely, 1152*8 
  // Shape of u_: input_capsule_num * (output_capsule_num * output_capsule_dim), namely, 1152*(16*10)
  // Shape of weights: input_capsule_num * input_capsule_dim * (output_capsule_num * output_capsule_dim), namely, 1152*8*10*16
  Dtype* u_data = u_.mutable_gpu_data();
  for(int i = 0; i < M_; ++i) {
    for(int j = 0; j < input_capsule_num_; ++j) {
      // 1*8 multiply 8*(16*10) = 1*(16*10)
      caffe_gpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, 1, total_output, input_capsule_dim_, (Dtype)1., 
	bottom_data_copy + i * total_input + j * input_capsule_dim_, 
		weight + j * input_capsule_dim_ * total_output, (Dtype)0., 
			u_data + i * input_capsule_num_ * total_output + j * total_output);
    }
  }

  // Dynamic routing
  //Dtype* scale_data = scale_.mutable_gpu_data();
  Dtype* c_data = c_.mutable_gpu_data();
  Dtype* s_data = s_.mutable_gpu_data();
  Dtype* v_data = v_.mutable_gpu_data();
  Dtype* b_data = b_.mutable_gpu_data();
  caffe_gpu_memcpy(M_ * routing_num, b_data, c_data);
  int routing_times = 3;
  for(int r = 0; r < routing_times; ++r) {
    kernel_channel_max<Dtype><<<CAFFE_GET_BLOCKS(M_ * output_capsule_num_), CAFFE_CUDA_NUM_THREADS>>>(M_, input_capsule_num_, output_capsule_num_, c_data, scale_data);
    kernel_channel_subtract<Dtype><<<CAFFE_GET_BLOCKS(M_* routing_num), CAFFE_CUDA_NUM_THREADS>>>(M_ * routing_num, M_, input_capsule_num_, output_capsule_num_, scale_data, c_data);
    kernel_exp<Dtype><<<CAFFE_GET_BLOCKS(M_ * routing_num), CAFFE_CUDA_NUM_THREADS>>>(M_ * routing_num, c_data, c_data);
    kernel_channel_sum<Dtype><<<CAFFE_GET_BLOCKS(M_ * output_capsule_num_), CAFFE_CUDA_NUM_THREADS>>>(M_, input_capsule_num_, output_capsule_num_, c_data, scale_data);
    kernel_channel_div<Dtype><<<CAFFE_GET_BLOCKS(M_ * routing_num), CAFFE_CUDA_NUM_THREADS>>>(M_ * routing_num, M_, input_capsule_num_, output_capsule_num_, scale_data, c_data);


    for(int ba = 0; ba < M_; ++ba) {
      for(int i = 0; i < input_capsule_num_; ++i) {
        for(int j = 0; j < output_capsule_num_; ++j) {
          LOG(INFO) << "probability: "<<c_data[ba * input_capsule_num_ * output_capsule_num + i * output_capsule_num_ + j];
	}
      }
    }




    //softmax(c_data, input_capsule_num_, output_capsule_num_, max_val, sum);
    for(int ba = 0; ba < M_; ++ba) {
      for(int i = 0; i < output_capsule_num_; ++i) {
        for(int j = 0; j < output_capsule_dim_; ++j) {
          caffe_gpu_gemm<Dtype>(CblasTrans, CblasTrans, 1, 1, input_capsule_num_, (Dtype)1., 
	    u_data + ba * total_output * input_capsule_num_ + i * output_capsule_dim_ * input_capsule_num_ + j * input_capsule_num_, 
		c_data + ba * output_capsule_num_ * input_capsule_num_ + i * input_capsule_num_, (Dtype)0., 
			s_data + ba * total_output + i * output_capsule_num_ + j);
	}
	squash(s_data + ba * total_output + i * output_capsule_dim_, output_capsule_dim_, v_data + ba * total_output + i * output_capsule_dim_, output_cap_vector);
      }
      Dtype out;
      for(int i = 0; i < input_capsule_num_; ++i) {
        for(int j = 0; j < output_capsule_num_; ++j) {
          //LOG(INFO) << "b_ shape 1: "<<b_.shape(1);
	  caffe_gpu_dot(output_capsule_dim_, v_data + ba * total_output + j * output_capsule_dim_, 
		u_data + ba * input_capsule_num_ * total_output + i * total_output + j * output_capsule_dim_, &out);
	  caffe_gpu_set(1, out, b_data + ba * routing_num + i * output_capsule_num_ + j);
	}
      }
    }
  }
        
    
  Dtype* top_data = top[0]->mutable_gpu_data();
  caffe_copy(M_ * total_output, v_.gpu_data(), top_data);
  if (bias_term_) {
    caffe_gpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, M_, output_capsule_num_, 1, (Dtype)1., bias_multiplier_.gpu_data(), this->blobs_[1]->gpu_data(), (Dtype)1., top_data);
  }
	
}


template <typename Dtype>
void CapLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
    const vector<bool>& propagate_down,
    const vector<Blob<Dtype>*>& bottom) {
  if (this->param_propagate_down_[0]) {
    const Dtype* top_diff = top[0]->gpu_diff();
    const Dtype* bottom_data = bottom[0]->gpu_data();
    // Gradient with respect to weight
    caffe_gpu_gemm<Dtype>(CblasTrans, CblasNoTrans, input_capsule_num_ * input_capsule_dim_, output_capsule_num_ * output_capsule_dim_, M_,
          (Dtype)1., bottom_data, top_diff,
          (Dtype)1., this->blobs_[0]->mutable_gpu_diff());
  }
  if (bias_term_ && this->param_propagate_down_[1]) {
    const Dtype* top_diff = top[0]->gpu_diff();
    // Gradient with respect to bias
    caffe_gpu_gemv<Dtype>(CblasTrans, M_, output_capsule_dim_ * output_capsule_num_, (Dtype)1., top_diff,
        bias_multiplier_.gpu_data(), (Dtype)1.,
        this->blobs_[1]->mutable_gpu_diff());
  }
  if (propagate_down[0]) {
    const Dtype* top_diff = top[0]->gpu_diff();
    // Gradient with respect to bottom data
    caffe_gpu_gemm<Dtype>(CblasNoTrans, CblasTrans, M_, input_capsule_num_ * input_capsule_dim_, output_capsule_num_ * output_capsule_dim_,
          (Dtype)1., top_diff, this->blobs_[0]->gpu_data(),
          (Dtype)0., bottom[0]->mutable_cpu_diff());
  }
}

INSTANTIATE_LAYER_GPU_FUNCS(CapLayer);

} 
